{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from subprocess import call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = ['contact-high-school', 'contact-primary-school']\n",
    "SG = 'sg'\n",
    "WORK_FOLDER = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Random Walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snap_node2vec import snap_node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for random walk sampling\n",
    "P = 1.\n",
    "N = 10\n",
    "WALKLEN = 80\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gudhi\n",
    "import k_simplex2vec as ks2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for DATASET in DATASETS:\n",
    "\n",
    "    save_path = WORK_FOLDER + 'processed-output/walks/%s/'%(DATASET)\n",
    "\n",
    "    cliques_train, _,data_train , _ = make_train_test_data(DATASET)\n",
    "\n",
    "    proj_g = nx.Graph([tuple(s) for s in data_train if len(s)==2])\n",
    "    proj_g.remove_edges_from(nx.selfloop_edges(proj_g))\n",
    "    max_comp = sorted(nx.connected_components(proj_g), key=len, reverse=True)[0]\n",
    "    proj_g = nx.subgraph(proj_g, max_comp)\n",
    "\n",
    "    nodes_train = set(proj_g.nodes())\n",
    "\n",
    "    simplices = list(map(tuple, [fs for fs in data_train if fs.issubset(nodes_train)]))\n",
    "\n",
    "    for k in range(MAX_ORDER):\n",
    "\n",
    "        if k==0:\n",
    "            node_name = np.array(list(proj_g.nodes()))\n",
    "            node_index = {node:index for index, node in enumerate(node_name)}\n",
    "            proj_g = nx.relabel_nodes(proj_g, node_index)\n",
    "            np.savez_compressed(save_path + '%dsimplex2vec_%s_maxorder%d.nodename.npz'%(k, 'uniform', k), node_name)\n",
    "\n",
    "            node2vec = snap_node2vec(d=2, max_iter=1, walk_len=80, num_walks=10, con_size=5, ret_p=1., inout_p=1.)\n",
    "            _ = node2vec.save_random_walks(proj_g, edge_f = None, is_weighted=False, \n",
    "                  no_python=True, directed=False, save_directory=save_path, \n",
    "                  file_name='%s_walks_%dsimplex2vec_%s_maxorder%d.txt'%('n%s_p%s'%(str(N),str(P)), k, 'uniform', k),\n",
    "                  compress=True)\n",
    "        else: \n",
    "\n",
    "            # Build a simplicial complex from the graph\n",
    "            st = gudhi.SimplexTree() #Gudhi simplex tree --> structure to store the simplices\n",
    "            for simplex in simplices:\n",
    "                st.insert(list(map(int, simplex)))\n",
    "\n",
    "            ## build transition matrix for the edges \n",
    "            p1 = ks2v.assemble(cplx =st, k=k, scheme=\"uniform\", laziness=None)\n",
    "            P1 = p1.astype(np.float32).toarray()\n",
    "\n",
    "            Simplices = list()\n",
    "            for simplex in st.get_filtration():\n",
    "                if simplex[1]!= np.inf:\n",
    "                    Simplices.append(simplex[0])\n",
    "                else: \n",
    "                    break  \n",
    "            assert(len(Simplices)==p1.shape[0])\n",
    "\n",
    "            node_name = np.array([','.join(map(str, sorted(map(int, n)))) for n in Simplices])\n",
    "            np.savez_compressed(save_path + '%dsimplex2vec_%s_maxorder%d.nodename.npz'%(k, 'uniform', k), node_name)\n",
    "\n",
    "            ## Perform random walks on the edges\n",
    "            Walks = ks2v.RandomWalks(walk_length=80, number_walks=10, P=P1)\n",
    "            walks_name = save_path + '%s_walks_%dsimplex2vec_%s_maxorder%d.txt'%('n%s_p%s'%(str(N),str(P)), k, 'uniform', k)\n",
    "            ks2v.save_random_walks(Walks, walks_name)\n",
    "\n",
    "            f_in = open(walks_name)\n",
    "            f_out = gzip.open(walks_name + '.gz', 'wt')\n",
    "            f_out.writelines(f_in)\n",
    "            f_out.close()\n",
    "            f_in.close()\n",
    "            call('rm ' + walks_name, shell=True)\n",
    "            \n",
    "        print('DONE:', DATASET, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train k-simplex2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 1.\n",
    "N = 10\n",
    "WALKLEN = 80\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embdim_list = [8, 16, 32, 64, 128, 256, 512, 1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for DATASET in DATASETS:\n",
    "\n",
    "    load_path = WORK_FOLDER + 'processed-output/walks/%s/'%(DATASET)\n",
    "    \n",
    "    for k in range(MAX_ORDER):\n",
    "\n",
    "        node_name = np.load(load_path\\\n",
    "                                +'%dsimplex2vec_%s_maxorder%d.nodename.npz'%(k, 'uniform', k))['arr_0']\n",
    "\n",
    "        walks_file = load_path\\\n",
    "               +'%s_walks_%dsimplex2vec_%s_maxorder%d.txt.gz'%('n%s_p%s'%(str(N),str(P)), k, 'uniform', k)\n",
    "\n",
    "        for EMBDIM in embdim_list:\n",
    "\n",
    "            PARAMS = '%s_%s_%s_%s' %\\\n",
    "                    ( 'dim'+str(EMBDIM), 'n'+str(N), 'p'+str(P), 'walklen'+str(WALKLEN))\n",
    "\n",
    "            save_path = WORK_FOLDER + 'processed-output/embeddings/%s/%s/'%(DATASET, PARAMS)\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "            save_file = save_path + '%d-s2vembs_%s_%s_maxorder%d.%s.pkl'\\\n",
    "                                        %(k, SG, 'uniform', k, SEED)\n",
    "\n",
    "            # fit word2vec\n",
    "            sents = LineSentence(walks_file)\n",
    "            model = Word2Vec(sentences=sents, min_count=1, sg=1, \n",
    "                             size=EMBDIM, window=10, \n",
    "                             seed=SEED, workers=30)\n",
    "\n",
    "            with open(save_file, 'wb') as fh:\n",
    "                pkl.dump(dict(zip(node_name[list(map(int, model.wv.index2word))], \n",
    "                              [_ for _ in model.wv.vectors])), fh, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "\n",
    "            print('DONE:', DATASET, k, EMBDIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
