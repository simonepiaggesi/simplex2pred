{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import networkx as nx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = ['contact-high-school', 'contact-primary-school']\n",
    "SG = 'sg'\n",
    "HASSE_TYPE = 'uniform'\n",
    "WORK_FOLDER = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 1.\n",
    "N = 10\n",
    "WALKLEN = 80\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TUPLE_SIZE = 3 # 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embdim_list = [8, 16, 32, 64, 128, 256, 512, 1024]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Reconstruction Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for DATASET in DATASETS:\n",
    "\n",
    "    hyperedges_path = WORK_FOLDER + 'processed-output/hyperedges/%s/'%(DATASET)\n",
    "\n",
    "    positive_ex = np.load(hyperedges_path + '%s_pos_%s_%dstring.npz'%('reconstruction', 'all', TUPLE_SIZE),\n",
    "                             allow_pickle=True)['arr_0']\n",
    "    negative_ex = np.load(hyperedges_path + '%s_neg_%s_%dstring.npz'%('reconstruction', 'all', TUPLE_SIZE),\n",
    "                             allow_pickle=True)['arr_0']\n",
    "    negative_bounds = np.load(hyperedges_path + '%s_neg_%s_%dbounds.npz'%('reconstruction', 'all', TUPLE_SIZE),\n",
    "                             allow_pickle=True)['arr_0']\n",
    "\n",
    "    for k in range(TUPLE_SIZE-1):\n",
    "\n",
    "        for EMBDIM in embdim_list:    \n",
    "            PARAMS = '%s_%s_%s_%s' %\\\n",
    "                        ( 'dim'+str(EMBDIM), 'n'+str(N), 'p'+str(P), 'walklen'+str(WALKLEN))\n",
    "\n",
    "            load_path = WORK_FOLDER + 'processed-output/embeddings/%s/%s/'%(DATASET, PARAMS)\n",
    "\n",
    "            save_path = WORK_FOLDER + 'processed-output/figures/%s/%s/'%(DATASET, PARAMS)\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "            if os.path.isdir(load_path):\n",
    "\n",
    "                #Load Embeddings\n",
    "                with open(load_path+'%d-s2vembs_%s_%s_maxorder%s.%s.pkl'%\\\n",
    "                            (k, SG, HASSE_TYPE, k, SEED), 'rb') as fh:\n",
    "                    model_wv = pkl.load(fh)\n",
    "                names = list(model_wv.keys())\n",
    "                index = dict(zip(names, range(len(names))))\n",
    "                model_wv = np.array([model_wv[n] for n in names])\n",
    "\n",
    "                for nlink in range(TUPLE_SIZE+1):\n",
    "\n",
    "                    for norder in [k]:\n",
    "\n",
    "                        if norder>0 and nlink<TUPLE_SIZE:\n",
    "                            continue\n",
    "\n",
    "                        results_file = save_path+'dict-reconstruction-%dbounds-%dsimplex-max5000-%s-%s-simplexorder%d-maxorder%d.pkl'%\\\n",
    "                                (nlink, norder, SG, HASSE_TYPE, TUPLE_SIZE-1, k)\n",
    "#                         if not os.path.isfile(results_file):\n",
    "                        \n",
    "                        dict_list = classification_score_from_x(positive_ex, \n",
    "                                                             negative_ex[negative_bounds==nlink], \n",
    "                                                             model_wv, index, norder)\n",
    "                        pkl.dump(dict_list, open(results_file, 'wb'), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "            \n",
    "                        print('DONE:', DATASET, TUPLE_SIZE, k, PARAMS, nlink, norder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction Scores - Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for DATASET in DATASETS:\n",
    "\n",
    "    save_path = WORK_FOLDER + 'processed-output/figures/%s/'%(DATASET)\n",
    "\n",
    "    for k in range(TUPLE_SIZE-1):\n",
    "        for nlink in range(TUPLE_SIZE+1):\n",
    "\n",
    "             for norder in [k]:\n",
    "\n",
    "                if norder>0 and nlink<TUPLE_SIZE:\n",
    "                    continue\n",
    "\n",
    "                output_file =save_path + '/best-aucpr-reconstruction-%dbounds-%dsimplex-max5000-%s-%s-simplexorder%d-maxorder%d.pkl'%\\\n",
    "                            (nlink, norder, SG, HASSE_TYPE, TUPLE_SIZE-1, k)\n",
    "\n",
    "#                 if not os.path.isfile(output_file):\n",
    "\n",
    "                best_dim_list = []\n",
    "\n",
    "                for EMBDIM in embdim_list:    \n",
    "                    PARAMS = '%s_%s_%s_%s' %\\\n",
    "                    ( 'dim'+str(EMBDIM), 'n'+str(N), 'p'+str(P), 'walklen'+str(WALKLEN))\n",
    "\n",
    "                    load_path = WORK_FOLDER + 'processed-output/figures/%s/%s/'%(DATASET, PARAMS)\n",
    "\n",
    "                    results_file = load_path + 'dict-reconstruction-%dbounds-%dsimplex-max5000-%s-%s-simplexorder%d-maxorder%d.pkl'%\\\n",
    "                            (nlink, norder, SG, HASSE_TYPE, TUPLE_SIZE-1, k)\n",
    "                    dict_list = pkl.load(open(results_file, 'rb'))\n",
    "                    recon_scores = [d['auc_pr'] if d['y_test'] is not None else None for d in dict_list] \n",
    "                    if recon_scores[0] is not None:\n",
    "                        best_dim_list.append((np.mean(recon_scores), EMBDIM))\n",
    "                    else:\n",
    "                        best_dim_list.append((None, EMBDIM))\n",
    "\n",
    "                BEST = sorted(best_dim_list, reverse=True)[0][1]\n",
    "                PARAMS = '%s_%s_%s_%s' %\\\n",
    "                    ( 'dim'+str(BEST), 'n'+str(N), 'p'+str(P), 'walklen'+str(WALKLEN))\n",
    "                load_path = WORK_FOLDER + 'processed-output/figures/%s/%s/'%(DATASET, PARAMS)\n",
    " \n",
    "                input_file = load_path + 'dict-reconstruction-%dbounds-%dsimplex-max5000-%s-%s-simplexorder%d-maxorder%d.pkl'%\\\n",
    "                            (nlink, norder, SG, HASSE_TYPE, TUPLE_SIZE-1, k)\n",
    "\n",
    "                dict_list = pkl.load(open(input_file, 'rb'))\n",
    "                pkl.dump(dict_list, open(output_file, 'wb'), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "                \n",
    "                print('DONE:', DATASET, TUPLE_SIZE, k, PARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Prediction Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for DATASET in DATASETS:\n",
    "\n",
    "    hyperedges_path = WORK_FOLDER + 'processed-output/hyperedges/%s/'%(DATASET)\n",
    "\n",
    "    positive_ex = np.load(hyperedges_path + '%s_pos_%s_%dstring.npz'%('prediction', 'all', TUPLE_SIZE),\n",
    "                             allow_pickle=True)['arr_0']\n",
    "    positive_bounds = np.load(hyperedges_path + '%s_pos_%s_%dbounds.npz'%('prediction', 'all', TUPLE_SIZE),\n",
    "                             allow_pickle=True)['arr_0']\n",
    "    negative_ex = np.load(hyperedges_path + '%s_neg_%s_%dstring.npz'%('prediction', 'all', TUPLE_SIZE),\n",
    "                             allow_pickle=True)['arr_0']\n",
    "    negative_bounds = np.load(hyperedges_path + '%s_neg_%s_%dbounds.npz'%('prediction', 'all', TUPLE_SIZE),\n",
    "                             allow_pickle=True)['arr_0']\n",
    "\n",
    "    for k in range(TUPLE_SIZE-1):\n",
    "\n",
    "        for EMBDIM in embdim_list:    \n",
    "            PARAMS = '%s_%s_%s_%s' %\\\n",
    "                        ( 'dim'+str(EMBDIM), 'n'+str(N), 'p'+str(P), 'walklen'+str(WALKLEN))\n",
    "\n",
    "            load_path = WORK_FOLDER + 'processed-output/embeddings/%s/%s/'%(DATASET, PARAMS)\n",
    "\n",
    "            save_path = WORK_FOLDER + 'processed-output/figures/%s/%s/'%(DATASET, PARAMS)\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "            if os.path.isdir(load_path):\n",
    "\n",
    "                #Load Embeddings\n",
    "                with open(load_path+'%d-s2vembs_%s_%s_maxorder%s.%s.pkl'%\\\n",
    "                            (k, SG, HASSE_TYPE, k, SEED), 'rb') as fh:\n",
    "                    model_wv = pkl.load(fh)\n",
    "                names = list(model_wv.keys())\n",
    "                index = dict(zip(names, range(len(names))))\n",
    "                model_wv = np.array([model_wv[n] for n in names])\n",
    "\n",
    "                for nlink in range(TUPLE_SIZE+1):\n",
    "\n",
    "                    for norder in [k]:\n",
    "\n",
    "                        if norder>0 and nlink<TUPLE_SIZE:\n",
    "                            continue\n",
    "\n",
    "                        results_file = save_path+'dict-prediction-%dbounds-%dsimplex-max5000-%s-%s-simplexorder%d-maxorder%d.pkl'%\\\n",
    "                                (nlink, norder, SG, HASSE_TYPE, TUPLE_SIZE-1, k)\n",
    "#                         if not os.path.isfile(results_file):\n",
    "                        \n",
    "                        dict_list = classification_score_from_x(positive_ex[positive_bounds==nlink], \n",
    "                                                             negative_ex[negative_bounds==nlink], \n",
    "                                                             model_wv, index, norder)\n",
    "                        pkl.dump(dict_list, open(results_file, 'wb'), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "            \n",
    "                        print('DONE:', DATASET, TUPLE_SIZE, k, PARAMS, nlink, norder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Scores - Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for DATASET in DATASETS:\n",
    "    \n",
    "    save_path = WORK_FOLDER + 'processed-output/figures/%s/'%(DATASET)\n",
    "\n",
    "    for k in range(TUPLE_SIZE-1):\n",
    "        for nlink in range(TUPLE_SIZE+1):\n",
    "\n",
    "             for norder in [k]:\n",
    "\n",
    "                if norder>0 and nlink<TUPLE_SIZE:\n",
    "                    continue\n",
    "\n",
    "                output_file =save_path + '/best-aucpr-prediction-%dbounds-%dsimplex-max5000-%s-%s-simplexorder%d-maxorder%d.pkl'%\\\n",
    "                            (nlink, norder, SG, HASSE_TYPE, TUPLE_SIZE-1, k)\n",
    "\n",
    "#                 if not os.path.isfile(output_file):\n",
    "\n",
    "                best_dim_list = []\n",
    "\n",
    "                for EMBDIM in embdim_list:    \n",
    "                    PARAMS = '%s_%s_%s_%s' %\\\n",
    "                    ( 'dim'+str(EMBDIM), 'n'+str(N), 'p'+str(P), 'walklen'+str(WALKLEN))\n",
    "\n",
    "                    load_path = WORK_FOLDER + 'processed-output/figures/%s/%s/'%(DATASET, PARAMS)\n",
    "\n",
    "                    results_file = load_path + 'dict-prediction-%dbounds-%dsimplex-max5000-%s-%s-simplexorder%d-maxorder%d.pkl'%\\\n",
    "                            (nlink, norder, SG, HASSE_TYPE, TUPLE_SIZE-1, k)\n",
    "                    dict_list = pkl.load(open(results_file, 'rb'))\n",
    "                    pred_scores = [d['auc_pr'] if d['y_test'] is not None else None for d in dict_list] \n",
    "                    if pred_scores[0] is not None:\n",
    "                        best_dim_list.append((np.mean(pred_scores), EMBDIM))\n",
    "                    else:\n",
    "                        best_dim_list.append((None, EMBDIM))\n",
    "\n",
    "                BEST = sorted(best_dim_list, reverse=True)[0][1]\n",
    "                PARAMS = '%s_%s_%s_%s' %\\\n",
    "                    ( 'dim'+str(BEST), 'n'+str(N), 'p'+str(P), 'walklen'+str(WALKLEN))\n",
    "                load_path = WORK_FOLDER + 'processed-output/figures/%s/%s/'%(DATASET, PARAMS)\n",
    "\n",
    "                \n",
    "                input_file = load_path + 'dict-prediction-%dbounds-%dsimplex-max5000-%s-%s-simplexorder%d-maxorder%d.pkl'%\\\n",
    "                            (nlink, norder, SG, HASSE_TYPE, TUPLE_SIZE-1, k)\n",
    "\n",
    "                dict_list = pkl.load(open(input_file, 'rb'))\n",
    "                pkl.dump(dict_list, open(output_file, 'wb'), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "                \n",
    "                print('DONE:', DATASET, TUPLE_SIZE, k, PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
